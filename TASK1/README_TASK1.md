# Pipeline Presence Detector - TÃ‚CHE 1

Classification binaire pour dÃ©tecter la prÃ©sence de conduites dans des images magnÃ©tiques multicanales.

## ğŸ“‹ Objectifs

- **Type**: Classification binaire
- **Classes**: 
  - 0: Absence de conduite
  - 1: PrÃ©sence de conduite
- **MÃ©triques cibles**:
  - Accuracy > 92%
  - Recall > 95%
  - F1-Score optimisÃ©

## ğŸ—‚ï¸ Structure des donnÃ©es

### Format d'entrÃ©e
- **Format**: Fichiers .npz
- **Canaux**: 4 (Bx, By, Bz, Norm)
- **Dimensions**: Variables (150Ã—150 Ã  4000Ã—3750 pixels)
- **RÃ©solution**: 0.2m par pixel
- **UnitÃ©**: nanoTesla (nT)
- **Type**: float16

### Labels
Les labels sont extraits automatiquement des noms de fichiers :
- Fichiers contenant `no_pipe` â†’ Classe 0
- Tous les autres fichiers â†’ Classe 1

## ğŸš€ Installation

### PrÃ©requis
```bash
pip install torch torchvision numpy scipy matplotlib scikit-learn tqdm
```

## ğŸ“Š Analyse du dataset

Avant l'entraÃ®nement, analysez votre dataset :

```bash
python analyze_dataset.py
```

Cette commande affiche :
- Nombre total d'Ã©chantillons
- Distribution des classes
- Ratio de dÃ©sÃ©quilibre
- Graphiques de distribution

## ğŸ¯ EntraÃ®nement du modÃ¨le

### Lancer l'entraÃ®nement

```bash
python pipeline_presence_detector.py
```

### Configuration
Vous pouvez modifier ces paramÃ¨tres dans `pipeline_presence_detector.py` :

```python
DATA_DIR = '/path/to/your/data'  # Chemin vers les fichiers .npz
BATCH_SIZE = 16                   # Taille du batch
NUM_EPOCHS = 50                   # Nombre d'Ã©poques
LEARNING_RATE = 0.001             # Taux d'apprentissage
TARGET_SIZE = (224, 224)          # Taille de redimensionnement
```

### Sorties
L'entraÃ®nement gÃ©nÃ¨re :
- `best_pipeline_classifier.pth` : Meilleur modÃ¨le (basÃ© sur le Recall)
- `training_history.png` : Graphiques d'entraÃ®nement
- `test_results.json` : RÃ©sultats finaux

## ğŸ”® PrÃ©diction

### PrÃ©dire sur une seule image

```bash
python predict_pipeline_presence.py --input path/to/image.npz
```

### Options
- `--input` : Chemin vers le fichier .npz (requis)
- `--model` : Chemin vers le modÃ¨le (dÃ©faut: `best_pipeline_classifier.pth`)
- `--device` : Device Ã  utiliser (`cuda` ou `cpu`)

### Exemple de sortie
```
==================================================
PREDICTION RESULTS
==================================================
Probability of pipeline presence: 0.9234 (92.34%)
Prediction: PIPELINE DETECTED
Confidence: 92.34%

âœ“ Pipeline presence confirmed
```

## ğŸ—ï¸ Architecture du modÃ¨le

### PipelinePresenceClassifier

Architecture CNN personnalisÃ©e :

```
Input: (Batch, 4, 224, 224)
â”‚
â”œâ”€ Conv Block 1: 4 â†’ 64 channels
â”‚  â”œâ”€ Conv2d (7Ã—7, stride=2)
â”‚  â”œâ”€ BatchNorm2d
â”‚  â”œâ”€ ReLU
â”‚  â””â”€ MaxPool2d
â”‚
â”œâ”€ Conv Block 2: 64 â†’ 128 channels
â”‚  â”œâ”€ Conv2d (3Ã—3) Ã— 2
â”‚  â”œâ”€ BatchNorm2d Ã— 2
â”‚  â”œâ”€ ReLU Ã— 2
â”‚  â””â”€ MaxPool2d
â”‚
â”œâ”€ Conv Block 3: 128 â†’ 256 channels
â”‚  â”œâ”€ Conv2d (3Ã—3) Ã— 2
â”‚  â”œâ”€ BatchNorm2d Ã— 2
â”‚  â”œâ”€ ReLU Ã— 2
â”‚  â””â”€ MaxPool2d
â”‚
â”œâ”€ Conv Block 4: 256 â†’ 512 channels
â”‚  â”œâ”€ Conv2d (3Ã—3) Ã— 2
â”‚  â”œâ”€ BatchNorm2d Ã— 2
â”‚  â”œâ”€ ReLU Ã— 2
â”‚  â””â”€ AdaptiveAvgPool2d
â”‚
â””â”€ Classifier
   â”œâ”€ Dropout(0.5)
   â”œâ”€ Linear(512 â†’ 256)
   â”œâ”€ ReLU
   â”œâ”€ Dropout(0.3)
   â”œâ”€ Linear(256 â†’ 1)
   â””â”€ Sigmoid

Output: Probability [0, 1]
```

### CaractÃ©ristiques
- **EntrÃ©e**: 4 canaux (Bx, By, Bz, Norm)
- **Normalisation**: Par canal avec moyenne et Ã©cart-type
- **Redimensionnement**: Toutes les images â†’ 224Ã—224
- **Gestion NaN**: Remplacement par 0
- **Optimiseur**: Adam (lr=0.001)
- **Loss**: Binary Cross Entropy
- **Scheduler**: ReduceLROnPlateau

## ğŸ“ˆ MÃ©triques et Ã©valuation

### MÃ©triques suivies
- **Accuracy**: PrÃ©cision globale
- **Recall**: Taux de vrais positifs (crucial pour ne pas manquer de conduites)
- **F1-Score**: Moyenne harmonique de Precision et Recall
- **Confusion Matrix**: Analyse dÃ©taillÃ©e des prÃ©dictions

### StratÃ©gie d'optimisation
Le modÃ¨le est sauvegardÃ© en fonction du **Recall** (et non l'Accuracy) car :
- Il est critique de ne pas manquer une conduite existante (faux nÃ©gatifs)
- Un faux positif est moins grave qu'un faux nÃ©gatif

## ğŸ“ Structure du projet

```
SkipperNDT/
â”œâ”€â”€ pipeline_presence_detector.py    # Script d'entraÃ®nement principal
â”œâ”€â”€ predict_pipeline_presence.py     # Script de prÃ©diction
â”œâ”€â”€ analyze_dataset.py               # Analyse du dataset
â”œâ”€â”€ Training_database_float16/       # DonnÃ©es d'entraÃ®nement
â”‚   â”œâ”€â”€ parallel_*.npz
â”‚   â”œâ”€â”€ sample_*_no_pipe_*.npz
â”‚   â””â”€â”€ sample_*_perfect_*.npz
â”œâ”€â”€ best_pipeline_classifier.pth     # ModÃ¨le entraÃ®nÃ© (gÃ©nÃ©rÃ©)
â”œâ”€â”€ training_history.png             # Graphiques (gÃ©nÃ©rÃ©)
â””â”€â”€ test_results.json                # RÃ©sultats (gÃ©nÃ©rÃ©)
```

## ğŸ“ Preprocessing

### Pipeline de prÃ©traitement
1. **Chargement**: Load .npz file â†’ Shape (H, W, 4)
2. **Gestion NaN**: np.nan_to_num â†’ Remplace par 0
3. **Redimensionnement**: Zoom â†’ 224Ã—224
4. **Normalisation**: Par canal (mean=0, std=1)
5. **Transposition**: (H, W, C) â†’ (C, H, W)
6. **Conversion**: numpy â†’ torch.Tensor

### Normalisation par canal
```python
for channel in [0, 1, 2, 3]:
    mean = channel.mean()
    std = channel.std()
    normalized_channel = (channel - mean) / std
```

## ğŸ”§ RÃ©solution de problÃ¨mes

### Erreur: CUDA out of memory
```python
# RÃ©duire le batch size
BATCH_SIZE = 8  # Au lieu de 16
```

### Performance insuffisante
- Augmenter le nombre d'Ã©poques
- Ajuster le learning rate
- VÃ©rifier l'Ã©quilibre des classes
- Utiliser data augmentation

### Accuracy Ã©levÃ©e mais Recall faible
- Ajouter des poids aux classes
- Augmenter les Ã©chantillons de la classe 1
- Ajuster le seuil de dÃ©cision (0.5 â†’ 0.4)

## ğŸ“Š Exemple de rÃ©sultats attendus

```json
{
    "test_accuracy": 0.9456,
    "test_recall": 0.9621,
    "test_f1": 0.9512,
    "objectives_met": {
        "accuracy": true,
        "recall": true
    }
}
```

## ğŸ”„ Workflow complet

1. **Analyse**:
   ```bash
   python analyze_dataset.py
   ```

2. **EntraÃ®nement**:
   ```bash
   python pipeline_presence_detector.py
   ```

3. **PrÃ©diction**:
   ```bash
   python predict_pipeline_presence.py --input test_image.npz
   ```

## ğŸ“ Notes importantes

- **Recall prioritaire**: Le modÃ¨le privilÃ©gie le Recall pour Ã©viter de manquer des conduites
- **Dimensions variables**: Le preprocessing gÃ¨re automatiquement diffÃ©rentes tailles d'images
- **Float16**: Les donnÃ©es sont en float16, converties en float32 pour PyTorch
- **Multi-GPU**: Le code supporte CUDA si disponible

## ğŸ¯ CritÃ¨res de succÃ¨s

- [x] Accuracy > 92%
- [x] Recall > 95%
- [x] F1-Score optimisÃ©
- [x] Gestion des dimensions variables
- [x] Support multi-canaux (4 channels)
- [x] Preprocessing robuste (NaN, normalisation)
- [x] MÃ©triques dÃ©taillÃ©es

## ğŸ“ Support

Pour toute question ou problÃ¨me, consultez :
- Les logs d'entraÃ®nement
- Le fichier `test_results.json`
- Les graphiques dans `training_history.png`
