"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PIPELINE PRESENCE DETECTOR - TÃ‚CHE 1
Classification Binaire pour la DÃ©tection de Conduites
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ RÃ‰SUMÃ‰ DU PROJET

Objectif:
  DÃ©velopper un classificateur binaire capable de dÃ©terminer si une image
  magnÃ©tique multicanale contient une conduite ou non.

DonnÃ©es:
  â€¢ Format: .npz (numpy compressed)
  â€¢ Canaux: 4 (Bx, By, Bz, Norm)
  â€¢ Dimensions: Variables (150Ã—150 Ã  4000Ã—3750 pixels)
  â€¢ UnitÃ©: nanoTesla (nT)
  â€¢ Dataset: 2833 Ã©chantillons
    - Classe 0 (No pipe): 1133 (40%)
    - Classe 1 (With pipe): 1700 (60%)

Objectifs de performance:
  âœ“ Accuracy > 92%
  âœ“ Recall > 95%
  âœ“ F1-Score optimisÃ©

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ FICHIERS CRÃ‰Ã‰S
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. SCRIPTS PRINCIPAUX
   â€¢ pipeline_presence_detector.py
     â†’ Script d'entraÃ®nement complet avec mÃ©triques
     â†’ Sauvegarde automatique du meilleur modÃ¨le
     â†’ GÃ©nÃ¨re graphiques et rapports
   
   â€¢ predict_pipeline_presence.py
     â†’ PrÃ©diction sur un fichier unique
     â†’ Affiche probabilitÃ© et confiance
   
   â€¢ batch_predict.py
     â†’ PrÃ©dictions en batch sur un dossier
     â†’ GÃ©nÃ¨re un fichier CSV de rÃ©sultats
   
   â€¢ visualize_predictions.py
     â†’ Visualise les prÃ©dictions sur Ã©chantillons
     â†’ Compare prÃ©dictions vs labels rÃ©els

2. SCRIPTS UTILITAIRES
   â€¢ analyze_dataset.py
     â†’ Analyse la distribution des classes
     â†’ VÃ©rifie l'Ã©quilibre et la taille du dataset
     â†’ GÃ©nÃ¨re des graphiques de distribution
   
   â€¢ test_system.py
     â†’ VÃ©rifie que tout fonctionne avant entraÃ®nement
     â†’ Tests unitaires du systÃ¨me complet

3. DOCUMENTATION
   â€¢ README_TASK1.md
     â†’ Documentation complÃ¨te du projet
     â†’ Architecture du modÃ¨le
     â†’ Guide d'utilisation dÃ©taillÃ©
   
   â€¢ INSTALLATION.md
     â†’ Guide d'installation pas Ã  pas
     â†’ RÃ©solution des problÃ¨mes
     â†’ Configuration recommandÃ©e

4. CONFIGURATION
   â€¢ requirements.txt
     â†’ Liste des dÃ©pendances Python
   
   â€¢ quick_start.sh
     â†’ Script de dÃ©marrage automatique

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ—ï¸ ARCHITECTURE DU MODÃˆLE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PipelinePresenceClassifier:
  â€¢ Type: CNN personnalisÃ©
  â€¢ EntrÃ©e: (Batch, 4, 224, 224)
  â€¢ Sortie: ProbabilitÃ© [0, 1]
  â€¢ ParamÃ¨tres: ~11M
  
  Structure:
    Block 1: 4 â†’ 64 channels   (Conv â†’ BatchNorm â†’ ReLU â†’ MaxPool)
    Block 2: 64 â†’ 128 channels  (ConvÃ—2 â†’ BatchNormÃ—2 â†’ ReLUÃ—2 â†’ MaxPool)
    Block 3: 128 â†’ 256 channels (ConvÃ—2 â†’ BatchNormÃ—2 â†’ ReLUÃ—2 â†’ MaxPool)
    Block 4: 256 â†’ 512 channels (ConvÃ—2 â†’ BatchNormÃ—2 â†’ ReLUÃ—2 â†’ AdaptivePool)
    Classifier: 512 â†’ 256 â†’ 1   (Dropout â†’ Linear â†’ ReLU â†’ Dropout â†’ Linear â†’ Sigmoid)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ WORKFLOW COMPLET
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ã‰TAPE 1: Installation
  $ pip install -r requirements.txt

Ã‰TAPE 2: VÃ©rification du systÃ¨me
  $ python test_system.py

Ã‰TAPE 3: Analyse du dataset
  $ python analyze_dataset.py
  
  GÃ©nÃ¨re:
    â€¢ dataset_distribution.png (graphiques)
    â€¢ Statistiques dÃ©taillÃ©es

Ã‰TAPE 4: EntraÃ®nement
  $ python pipeline_presence_detector.py
  
  GÃ©nÃ¨re:
    â€¢ best_pipeline_classifier.pth (modÃ¨le)
    â€¢ training_history.png (courbes d'entraÃ®nement)
    â€¢ test_results.json (rÃ©sultats finaux)
  
  DurÃ©e estimÃ©e:
    â€¢ CPU: 4-6 heures
    â€¢ GPU: 30-60 minutes

Ã‰TAPE 5: PrÃ©diction

  5a. PrÃ©diction unique:
    $ python predict_pipeline_presence.py --input fichier.npz
  
  5b. PrÃ©dictions batch:
    $ python batch_predict.py --input_dir dossier/
    
    GÃ©nÃ¨re:
      â€¢ batch_results.csv
  
  5c. Visualisation:
    $ python visualize_predictions.py --samples 9
    
    GÃ©nÃ¨re:
      â€¢ predictions_visualization.png

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š MÃ‰TRIQUES ET Ã‰VALUATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MÃ©triques suivies pendant l'entraÃ®nement:
  â€¢ Loss (Train & Validation)
  â€¢ Accuracy (Train & Validation)
  â€¢ Recall (Validation) â† CritÃ¨re principal de sauvegarde
  â€¢ F1-Score (Validation)

Ã‰valuation finale (Test set):
  â€¢ Accuracy
  â€¢ Recall
  â€¢ F1-Score
  â€¢ Confusion Matrix
  â€¢ Classification Report

StratÃ©gie:
  Le modÃ¨le est sauvegardÃ© selon le RECALL (pas l'Accuracy) car il est
  critique de ne pas manquer une conduite existante (faux nÃ©gatifs).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”§ PREPROCESSING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Pipeline automatique:
  1. Chargement du .npz
  2. Gestion des NaN â†’ remplacÃ©s par 0
  3. Redimensionnement â†’ 224Ã—224 (zoom intelligent)
  4. Normalisation par canal â†’ mean=0, std=1
  5. Transposition â†’ (H,W,C) â†’ (C,H,W)
  6. Conversion â†’ numpy â†’ torch.Tensor

Avantages:
  âœ“ GÃ¨re les dimensions variables automatiquement
  âœ“ Normalisation robuste
  âœ“ Pas de perte de donnÃ©es importantes
  âœ“ OptimisÃ© pour PyTorch

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’¡ FEATURES CLÃ‰S
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Support multi-canaux (4 channels: Bx, By, Bz, Norm)
âœ“ Dimensions d'entrÃ©e variables (gÃ©rÃ©es automatiquement)
âœ“ Gestion robuste des NaN et valeurs infinies
âœ“ Normalisation adaptative par canal
âœ“ Support GPU/CPU avec dÃ©tection automatique
âœ“ Data splitting stratifiÃ© (train/val/test)
âœ“ Learning rate scheduling adaptatif
âœ“ Sauvegarde du meilleur modÃ¨le (basÃ©e sur Recall)
âœ“ MÃ©triques complÃ¨tes et visualisations
âœ“ PrÃ©dictions batch avec export CSV
âœ“ Documentation complÃ¨te
âœ“ Tests unitaires du systÃ¨me

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ POINTS D'ATTENTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. MÃ©moire:
   â€¢ Si "CUDA out of memory": rÃ©duire BATCH_SIZE (16 â†’ 8)
   â€¢ Sur CPU: prÃ©voir 8+ GB RAM

2. DonnÃ©es:
   â€¢ VÃ©rifier le chemin DATA_DIR dans le code
   â€¢ S'assurer que les fichiers .npz sont accessibles

3. Performance:
   â€¢ Recall > Accuracy (prioritÃ© aux faux nÃ©gatifs)
   â€¢ EntraÃ®nement long sur CPU (utiliser GPU si possible)

4. DataLoader:
   â€¢ Si erreurs "worker": mettre num_workers=0

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ˆ RÃ‰SULTATS ATTENDUS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Avec le dataset actuel (2833 Ã©chantillons, ratio 1.5:1):

Optimiste:
  â€¢ Accuracy: 94-96%
  â€¢ Recall: 96-98%
  â€¢ F1-Score: 95-97%

RÃ©aliste:
  â€¢ Accuracy: 92-94%
  â€¢ Recall: 95-96%
  â€¢ F1-Score: 93-95%

Conservateur:
  â€¢ Accuracy: 90-92%
  â€¢ Recall: 93-95%
  â€¢ F1-Score: 91-93%

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ CRITÃˆRES DE SUCCÃˆS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Objectifs OBLIGATOIRES:
  âœ“ Accuracy > 92%
  âœ“ Recall > 95%
  âœ“ Minimum 500 Ã©chantillons labellisÃ©s

Objectifs BONUS:
  âœ“ F1-Score > 93%
  âœ“ Support dimensions variables
  âœ“ Preprocessing robuste
  âœ“ Visualisations automatiques
  âœ“ Documentation complÃ¨te

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ COMMANDES RAPIDES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Installation
pip install -r requirements.txt

# Tests
python test_system.py

# Analyse
python analyze_dataset.py

# EntraÃ®nement
python pipeline_presence_detector.py

# PrÃ©diction
python predict_pipeline_presence.py --input test.npz

# Batch
python batch_predict.py --input_dir dossier/

# Visualisation
python visualize_predictions.py --samples 9

# Tout automatique
./quick_start.sh

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… CHECKLIST DE VALIDATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Avant de commencer:
  [ ] Python 3.8+ installÃ©
  [ ] DÃ©pendances installÃ©es (pip install -r requirements.txt)
  [ ] test_system.py passe tous les tests
  [ ] Dataset accessible et analysÃ©

AprÃ¨s l'entraÃ®nement:
  [ ] Accuracy > 92%
  [ ] Recall > 95%
  [ ] Fichiers gÃ©nÃ©rÃ©s (model, history, results)
  [ ] PrÃ©dictions testÃ©es sur Ã©chantillons
  [ ] Visualisations crÃ©Ã©es

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ce systÃ¨me est prÃªt Ã  l'emploi pour la TÃ‚CHE 1 du projet SkipperNDT.
Pour plus de dÃ©tails, consultez README_TASK1.md et INSTALLATION.md.

Bonne chance! ğŸš€
"""

if __name__ == "__main__":
    print(__doc__)
